<!DOCTYPE HTML>
<html>

<head>
    <title>Research Methods and Professional Practice</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript>
        <link rel="stylesheet" href="assets/css/noscript.css" />
    </noscript>
</head>

<body class="is-preload">
    <!-- Wrapper -->
    <div id="wrapper">
        <!-- Header -->
        <!-- Note: The "styleN" class below should match that of the banner element. -->
        <header id="header" class="alt style2">
            <a href="index.html" class="logo"><strong>e-Portfolio</strong> <span>by Dalbir Singh</span></a>
            <nav>
                <a href="#menu">Menu</a>
            </nav>
        </header>
        <!-- Menu -->
        <nav id="menu">
            <ul class="links">
                <li><a href="index.html">Home</a></li>
                <li><a href="landing.html">Landing</a></li>
                <li><a href="generic.html">Generic</a></li>
                <li><a href="elements.html">Elements</a></li>
            </ul>
            <ul class="actions stacked">
                <li><a href="#" class="button primary fit">Get Started</a></li>
                <li><a href="#" class="button fit">Log In</a></li>
            </ul>
        </nav>
        <!-- Banner -->
        <!-- Note: The "styleN" class below should match that of the header element. -->
        <section id="banner" class="style2">
            <div class="inner">
                <span class="image">
                    <img src="images/pic07.jpg" alt="" />
                </span>
                <header class="major">
                    <h1>Research Methods and Professional Practice</h1>
                </header>
                <div class="content">
                    <p>August 2025 - October 2025</p>
                </div>
            </div>
        </section>
        <!-- Main -->
        <div id="main">
            <!-- Three -->
            <section id="three">
                <div class="inner">
                    <div class="table_of_contents">
                        <table>
                            <thead>
                                <tr>
                                    <th><b>Contents</b></th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td><a href="#section1">1. Reflective Activity 1 - Ethics in Computing in the Age of
                                            Generative AI</a></td>
                                <tr>
                                    <td><a href="#section2">2. Outline of Literature Review and Research Proposal</a>
                                    </td>
                                </tr>
                                <tr>
                                    <td><a href="#section3">3. Summary of Collaborative Discussion 1</a>
                                    </td>
                                </tr>
                                <tr>
                                    <td><a href="#section4">4. Summary of Collaborative Discussion 2</a></td>
                                </tr>
                                <tr>
                                    <td><a href="#section5">5. Research Proposal Review</a></td>
                                </tr>
                                <tr>
                                    <td><a href="#section6">6. Peer Review Activity</a></td>
                                </tr>
                                <tr>
                                    <td><a href="#section7">7. Reflective Activity 2 - Case Study: Inappropriate Use of
                                            Surveys</a></td>
                                </tr>
                                <tr>
                                    <td><a href="#section8">8. Hypothesis Testing Worksheet</a></td>
                                </tr>
                                <tr>
                                    <td><a href="#section9">9. Summary Measures Worksheet</a></td>
                                </tr>
                                <tr>
                                    <td><a href="#section10">10. Analysing Datasets</a></td>
                                </tr>
                                <tr>
                                    <td><a href="#section11">11. Analysing Bar Charts in Excel</a></td>
                                </tr>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                    <div class="reflective_activity_1">
                        <header>
                            <h2 id="section1">1. Reflective Activity 1 - Ethics in Computing in the Age of
                                Generative AI
                            </h2>
                        </header>
                        <p>
                            Since late 2022, I’ve seen how generative AI has rapidly moved from a niche technology to
                            something that’s reshaping nearly every industry and even the way we live and work. As
                            someone studying and working within computing, this shift has felt especially personal.
                            Generative AI didn’t appear out of nowhere, it builds on decades of research, and yet the
                            urgency around ethical guidelines now feels more important than ever. I was particularly
                            struck by Correa et al. (2023), who describe this moment as an “AI ethics boom”, a global
                            scramble to figure out how AI should be governed. But after reading both Correa et al. and
                            Deckard (2023), I’m left feeling that while we’ve made progress, we still lack a consistent,
                            actionable approach to ethics in AI. This is something I think needs to change.
                            <br><br>
                            Correa et al. (2023) highlights that a lot of work is being done to define the values
                            guiding AI, but it’s clear there’s little global agreement. Countries and organizations have
                            released hundreds of guidelines, yet many are vague, voluntary, or overlap in unhelpful
                            ways. Their study reviewed 200 such documents and found 17 recurring principles, including
                            transparency, fairness, accountability, and privacy. What stood out to me was how different
                            regions and institutions emphasize different priorities. For example, European countries
                            focus more on privacy and human rights, while the U.S. tends to highlight innovation and
                            reliability. Asian countries often place emphasis on beneficence and collective good. This
                            divergence isn’t surprising, given the different political and cultural contexts, but it
                            raises a serious question. How can we move forward if we don’t even agree on what we’re
                            trying to protect?
                            <br><br>
                            One of the issues Correa et al. also point out is that many of these ethical principles
                            aren’t backed by enforcement. The majority of guidelines they reviewed are not legally
                            binding, and very few provide practical tools to put the principles into action. I think
                            this is one of the biggest weaknesses in our current approach. Ethics can’t just be
                            theoretical, it needs to shape real-world decisions. I’ve seen examples where AI tools are
                            deployed quickly without fully understanding the risks. This can lead to harmful
                            consequences, especially for vulnerable groups. The Cambridge Analytica scandal or the
                            biased risk scores used in criminal justice software (Angwin et al., 2016) are just a few
                            examples. In my opinion, without enforceable standards or technical mechanisms, ethics in AI
                            risks becoming more of a checkbox exercise than something meaningful.
                            <br><br>
                            Deckard (2023) takes a more practical approach, focusing on what it means to be an AI
                            ethicist today. I found this really useful because it gave me a clearer idea of how ethics
                            should be part of everyday practice, not just something we think about when something goes
                            wrong. He talks about the importance of having a background in both technology and
                            philosophy, staying informed, and being able to communicate ethical ideas clearly. What
                            resonated most with me was the idea that we need to develop practical solutions to ethical
                            challenges. It’s not enough to say that AI should be fair or transparent. We need tools,
                            frameworks, and processes that help developers and organizations implement those values.
                            <br><br>
                            In terms of what I think should happen next, I believe there needs to be a more coordinated
                            international effort to create baseline standards for AI ethics, ones that are legally
                            binding and come with enforcement mechanisms. I don’t mean that every country has to adopt
                            the exact same approach, but there should be some agreement on minimum protections. For
                            example, all AI systems should be subject to impact assessments, especially if they’re used
                            in high-risk areas like healthcare, law enforcement, or education. These assessments should
                            consider not just technical performance but social and ethical implications as well (Morley
                            et al., 2020).
                            <br><br>
                            Also, as a computing professional, I think there’s a responsibility on us to push back when
                            things don’t feel right. The BCS Code of Conduct (BCS, 2024) makes it clear that we need to
                            consider the wellbeing, privacy, and safety of the public. But in reality, developers often
                            face pressure to release products quickly, even if the ethical concerns haven’t been fully
                            addressed. I think this tension between speed and responsibility is one of the biggest
                            challenges in the tech industry right now. Companies need to create environments where
                            ethical concerns are taken seriously and where professionals are supported if they raise red
                            flags.
                            <br><br>
                            At the same time, I agree with Deckard (2023) that ethics can’t just be left to ethicists.
                            Everyone involved in developing or deploying AI systems should have at least a basic
                            understanding of ethical issues. This means integrating ethics more deeply into computer
                            science education, not just as a separate module, but across all parts of the curriculum.
                            Courses in AI should include discussions of fairness, data bias, and user consent alongside
                            the technical content. I also think professional certifications should include ethics as a
                            core component, especially for those working in high-impact areas.
                            <br><br>
                            If we took these steps, the legal, social, and professional impacts could be significant.
                            Legally, there would be clearer accountability when things go wrong, and we’d likely see
                            fewer cases of unethical AI use. Socially, people might start to trust AI systems more,
                            especially if they know those systems have been reviewed for fairness and safety.
                            Professionally, I think the role of the computing professional would become even more
                            complex, but also more respected. We’d no longer be just coders or engineers, we’d also be
                            guardians of the public interest.
                            <br><br>
                            The rapid rise of generative AI has made ethics more important than ever. Correa et al.
                            (2023) show that while there’s a growing awareness of ethical issues globally, our current
                            frameworks are fragmented and too soft. Deckard (2023) helps highlight how we, as
                            individuals, can start to take action by building skills and participating in ethical
                            discussions. But ultimately, we need structural change: enforceable global standards, more
                            practical tools, and better ethics education. In this way, we can ensure that AI truly
                            benefits everyone, and not just a few powerful players.
                            <br><br>
                            <b>References</b>
                        <ul>
                            <li>Angwin, J., Larson, J., Mattu, S. and Kirchner, L. (2016) Machine Bias. ProPublica.
                                Available at:
                                https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
                                (Accessed: 6 August 2025).</li>
                            <li>BCS (2024) BCS Code of Conduct. Available at:
                                https://www.bcs.org/membership/become-a-member/bcs-code-of-conduct/ (Accessed: 6 August
                                2025).
                            </li>
                            <li>Correa, N., Galvão, C., Santos, J.W., Del Pino, C., Pontes Pinto, E., Barbosa, C.,
                                Massmann, D., Mambrini, R., Galvão, L., Terem, E. and de Oliveira, N. (2023) ‘Worldwide
                                AI ethics: A review of 200 guidelines and recommendations for AI governance’, Patterns,
                                4(10), p. 100857. https://doi.org/10.1016/j.patter.2023.100857.
                            </li>
                            <li>Deckard, R. (2023) ‘What are ethics in AI?’, BCS – The Chartered Institute for IT, 3
                                April. Available at: https://www.bcs.org/articles-opinion-and-research/article/
                                (Accessed: 6 August 2025).
                            </li>
                            <li>Morley, J., Cowls, J., Taddeo, M. and Floridi, L. (2020) ‘Ethical guidelines for
                                COVID-19 tracing apps’, Nature, 582, pp. 29–31.
                                https://doi.org/10.1038/d41586-020-01578-0.
                            </li>
                        </ul>
                        </p>
                        <br>
                    </div>
                    <div class="literature_review_and_research_proposal_outline">
                        <header>
                            <h2 id="section2">3. Outline of Literature Review and Research Proposal</h2>
                        </header>
                        <p><a
                                href="https://github.com/dasing21/eportfolio/tree/main/research_methods/outline_of_literature_review_and_research_proposal/outline_of_literature_review_and_research_proposal">Link
                                to solution in GitHub:</a></p>
                        <br>
                    </div>
                    <div class="collaborative_discussion_1">
                        <header>
                            <h2 id="section3">3. Summary of Collaborative Discussion 1
                            </h2>
                        </header>
                        <p>
                            The Accessibility in Software Development case study highlights the ethical dilemma of
                            balancing client deadlines with the responsibility to create inclusive products. My initial
                            analysis emphasised that omitting accessibility features risks discriminating against users
                            with disabilities, violating ACM Principles 1.1 (contribute to society) and 1.4 (act fairly
                            and avoid discrimination) (ACM, 2018), as well as BCS duties to uphold equality, diversity,
                            and public interest (BCS, 2024). Such omissions can also trigger legal consequences under
                            frameworks like the UK Equality Act 2010 and WCAG standards (W3C, 2018).
                            <br><br>
                            Peer feedback from Julius Cloos deepened this perspective by highlighting ACM Principle 1.2,
                            which stresses adherence to best practices, and Principle 2.3, which encourages following
                            professional standards to avoid wasted effort on inaccessible features (Horton, 2025).
                            Implementing accessibility from the outset not only aligns with ethical codes, but also
                            prevents inefficiencies and reputational damage.
                            <br><br>
                            The peer feedback from Md Chowdhury reinforced that accessibility should be treated as a
                            core quality attribute, comparable to security or performance. Building it in early reduces
                            technical debt, minimises costly rework, and demonstrates a commitment to inclusive design
                            as a business value. This framing can help secure stakeholder buy-in, even under tight
                            deadlines.
                            <br><br>
                            Both the ACM and BCS codes frame accessibility as an ethical imperative, not an optional
                            enhancement. The discussion confirms that proactive, integrated accessibility practices
                            support legal compliance, uphold professional integrity, and strengthen trust with users.
                            Balancing commercial pressures with these responsibilities ensures technology serves all
                            members of society, fulfilling the broader purpose of the computing profession.
                            <br><br>
                            <b>References</b>
                        <ul>
                            <li>ACM (2018) ACM Code of Ethics and Professional Conduct. Available at:
                                https://www.acm.org/code-of-ethics (Accessed: 23 September 2025).</li>
                            <li>BCS (2024) BCS Code of Conduct. Available at:
                                https://www.bcs.org/membership/become-a-member/bcs-code-of-conduct/ (Accessed: 23
                                September 2025).
                            </li>
                            <li>Horton, S. (2025) Case Study: Accessibility in Software Development. Available at:
                                https://www.acm.org/code-of-ethics/case-studies/accessibility-in-software-development
                                (Accessed: 23
                                September 2025).
                            </li>
                            <li>W3C (2018) Web Content Accessibility Guidelines (WCAG) 2.1. Available at:
                                https://www.w3.org/TR/WCAG21/ (Accessed: 23
                                September 2025).
                            </li>
                        </ul>
                        </p>
                        <br>
                    </div>
                    <div class="collaborative_discussion_2">
                        <header>
                            <h2 id="section4">4. Summary of Collaborative Discussion 2
                            </h2>
                        </header>
                        <p>
                            The case of Abi and the Whizzz cereal study has prompted a valuable exchange on integrity,
                            responsibility, and the pressures of commercial interest. My initial post argued that Abi’s
                            duty is to present the data transparently, reflecting both positive and negative findings.
                            This position aligns with the ACM Code of Ethics (2018) and the BCS Code of Conduct (2024),
                            which stress honesty, the avoidance of harm, and the protection of the public interest.
                            <br><br>
                            Valentina’s responses reinforced that data integrity is fundamental to sustaining public
                            trust in science. Once findings are perceived as biased or manipulated, credibility is
                            difficult to restore. This aligns with O’Neil’s (2016) critique that misapplied statistical
                            models can have far-reaching societal consequences. The point that responsibility extends
                            beyond one company or study is well made; the perception of bias can erode confidence in
                            entire professions.
                            <br><br>
                            Valentina also asked whether Abi could ever justify prioritising the manufacturer’s
                            interests, for instance if the “harmful” results came from a small sample or weak
                            statistical test. I would argue that even in such cases, Abi cannot ethically suppress or
                            downplay those results. Instead, he should report them transparently with clear caveats
                            about sample size, robustness, and uncertainty. The European Food Safety Authority (2019)
                            guidance on uncertainty emphasises that limitations must be communicated explicitly so
                            stakeholders understand the strength of the evidence. Suppressing unfavourable outcomes
                            risks misleading stakeholders, violating ethical codes, and undermining trust.
                            <br><br>
                            In conclusion, Abi’s responsibility is not only technical but moral. By reporting fully and
                            contextualising uncertainty, he upholds professional integrity, safeguards public health,
                            and protects the credibility of both science and computing practice.
                            <br><br>
                            <b>References</b>
                        <ul>
                            <li>ACM (2018) ACM Code of Ethics and Professional Conduct. Available at:
                                https://www.acm.org/code-of-ethics (Accessed: 23 September 2025).</li>
                            <li>BCS (2024) BCS Code of Conduct. Available at:
                                https://www.bcs.org/membership/become-a-member/bcs-code-of-conduct/ (Accessed: 23
                                September 2025).
                            </li>
                            <li>European Food Safety Authority (2019) ‘Guidance on communication of uncertainty in
                                scientific assessments’, EFSA Journal, 17(1), e05520. Available at:
                                https://doi.org/10.2903/j.efsa.2019.5520 (Accessed: 23 September 2025).
                            </li>
                            <li>O’Neil, C. (2016) Weapons of math destruction: How big data increases inequality and
                                threatens democracy. New York: Crown.
                            </li>
                        </ul>
                        </p>
                        <br>
                    </div>
                    <div class="research_proposal_review">
                        <header>
                            <h2 id="section5">5. Research Proposal Review</h2>
                        </header>
                        <p><a
                                href="https://github.com/dasing21/eportfolio/tree/main/research_methods/research_proposal_review/research_proposal_review.docx">Link
                                to solution in GitHub:</a></p>
                        <br>
                    </div>
                    <div class="peer_review_activity">
                        <header>
                            <h2 id="section6">6. Peer Review Activity</h2>
                        </header>
                        <p><a
                                href="https://github.com/dasing21/eportfolio/tree/main/research_methods/peer_review_activity/peer_review_activity.docx">Link
                                to solution in GitHub:</a></p>
                        <br>
                    </div>
                    <div class="reflective_activity_2">
                        <header>
                            <h2 id="section7">7. Reflective Activity 2 - Case Study: Inappropriate Use of Surveys
                            </h2>
                        </header>
                        <h3>Cambridge Analytica - what happened and why oversight failed</h3>
                        <p>
                            A Facebook “personality quiz” (“This Is Your Digital Life”) collected respondents’ answers
                            and their friends’ profile data via the then-available API, enabling large-scale
                            psychographic profiling and political micro-targeting beyond any reasonable interpretation
                            of informed consent (Confessore, 2018). Oversight failed due to weak platform governance
                            (permissive default friend-data access and light app vetting), over-reliance on
                            self-regulation, and regulatory lag, subsequent investigations and sanctions emphasised
                            lawfulness and transparency in political data analytics (ICO, 2018; FTC, 2019). From a
                            research-methods perspective, the consent pathway was not compliant with the Belmont
                            principles (respect, beneficence, justice) and breached basic standards on purpose
                            limitation and data minimisation (HHS, 1979/2024).
                            <br>
                        <h3>Comparative cases - distinctive ethical failings</h3>
                        myPersonality (academic quiz). The project accumulated millions of survey responses, then
                        distributed large datasets to numerous external parties under weak access controls; Facebook
                        later banned the app following an audit (Kapoor, 2018; Lomas, 2018; The Psychometrics Centre,
                        n.d.). Some of the distinct issues were research framing without robust, ongoing governance,
                        consent that did not clearly bound secondary use, inadequate anonymisation and data-sharing
                        controls. Methodologically, this contravenes good survey practice (clear consent scope, strong
                        de-identification, Data Use Agreements, and, where applicable, ethics/IRB oversight).
                        <br><br>
                        Nametests.com (viral quizzes). A security flaw exposed users’ profile data at massive scale, the
                        issue was reported by a researcher and later fixed (De Ceukelaire, 2018; Robertson, 2018). Some
                        distinct issues were failure of security-by-design, token handling, and third-party access
                        hygiene, illustrating how even trivial “fun” surveys can create systemic privacy risk when
                        protection and data minimisation are absent.
                        <br><br>
                        <h3>Ethical, social, legal and professional impacts</h3>
                        Ethical (research design):
                        <ul>
                            <li>Covert secondary use and broad data capture fail informed consent, beneficence, and
                                justice
                                (HHS, 1979/2024).</li>
                        </ul>
                        Social:
                        <ul>
                            <li>Erosion of public trust and risk to democratic discourse via opaque micro-targeting
                                (ICO,
                                2018).</li>
                        </ul>
                        Legal/regulatory:
                        <ul>
                            <li>Enforcement escalated post-2018 (for example FTC’s $5 billion settlement with Facebook,
                                ICO
                                investigations), underscoring that platform governance and app vetting are compliance
                                obligations, not merely reputational concerns (ICO, 2018; FTC, 2019).</li>
                        </ul>
                        Professional conduct:
                        <ul>
                            <li>The ACM Code of Ethics requires respecting privacy and honouring confidentiality, using
                                surveys as a data-collection pretext conflicts with duties to avoid harm and act in the
                                public interest (ACM, 2018).</li>
                        </ul>
                        <br>
                        <h3>To summarize</h3>
                        State a specific purpose and obtain granular, opt-in consent for any secondary use, minimise
                        data (no friend harvesting, avoid identifiability unless essential), implement privacy/security
                        by design (app review, monitoring, revocation), control sharing through DUAs and audits, and
                        ensure appropriate ethics/IRB review for human-participant surveys (ICO, 2018; FTC, 2019; HHS,
                        1979/2024; ACM, 2018).
                        <br><br>
                        <b>References</b>
                        <br><br>
                        <ul>
                            <li>ACM (2018) ACM Code of Ethics and Professional Conduct. Available at:
                                https://www.acm.org/code-of-ethics (Accessed: 29 August 2025).</li>
                            <li>Confessore, N. (2018) ‘Cambridge Analytica and Facebook: The scandal and the fallout so
                                far’, The New York Times, 4 April. Available at: https://www.nytimes.com/ (Accessed: 29
                                August 2025).
                            </li>

                            <li>De Ceukelaire, I. (2018) ‘This popular Facebook app publicly exposed your data for
                                years’, Medium, 28 June. Available at:
                                https://medium.com/@intideceukelaire/this-popular-facebook-app-publicly-exposed-your-data-for-years-12483418eff8
                                (Accessed: 29 August 2025).
                            </li>
                            <li>Federal Trade Commission (2019) ‘FTC imposes $5 billion penalty and sweeping new privacy
                                restrictions on Facebook’, Press release, 24 July. Available at:
                                https://www.ftc.gov/news-events/news/press-releases/2019/07/ftc-imposes-5-billion-penalty-sweeping-new-privacy-restrictions-facebook
                                (Accessed: 29 August 2025).
                            </li>
                            <li>HHS (US Department of Health and Human Services) (1979/2024) The Belmont Report: Ethical
                                principles and guidelines for the protection of human subjects of research. Available
                                at: https://www.hhs.gov/ohrp/sites/default/files/the-belmont-report-508c_FINAL.pdf
                                (Accessed: 29 August 2025).
                            </li>
                            <li>
                                ICO (Information Commissioner’s Office) (2018) Investigation into the use of data
                                analytics in political campaigns – Final report (5 November). Available at:
                                https://ico.org.uk/media2/migrated/2260271/investigation-into-the-use-of-data-analytics-in-political-campaigns-final-20181105.pdf
                                (Accessed: 29 August 2025).
                            </li>
                            <li>
                                Kapoor, N. (2018) ‘Facebook data on 3 million users reportedly exposed by personality
                                app’, The Verge, 14 May. Available at:
                                https://www.theverge.com/2018/5/14/17352900/facebook-data-exposed-personality-quiz
                                (Accessed: 29 August 2025).
                            </li>
                            <li>
                                Lomas, N. (2018) ‘Facebook bans first app since Cambridge Analytica: myPersonality, and
                                suspends hundreds more’, TechCrunch, 22 August. Available at:
                                https://techcrunch.com/2018/08/22/facebook-bans-first-app-since-cambridge-analytica-mypersonality-and-suspends-hundreds-more/
                                (Accessed: 29 August 2025).
                            </li>
                            <li>
                                Robertson, A. (2018) ‘Maker of popular quiz apps on Facebook exposed personal data of
                                120 million users’, The Verge, 28 June. Available at:
                                https://www.theverge.com/2018/6/28/17514822/facebook-data-leak-quiz-app-nametests-social-sweetheart-exposed-user-info
                                (Accessed: 29 August 2025).
                            </li>
                            <li>
                                The Psychometrics Centre (n.d.) myPersonality database. University of Cambridge.
                                Available at: https://www.psychometrics.cam.ac.uk/productsservices/mypersonality
                                (Accessed: 29 August 2025).
                            </li>
                        </ul>
                        </p>
                    </div>
                    <div class="hypothesis_testing_worksheet">
                        <header>
                            <h2 id="section8">8. Hypothesis Testing Worksheet</h2>
                        </header>
                        <p><a
                                href="https://github.com/dasing21/eportfolio/tree/main/research_methods/hypothesis_testing_worksheet/hypothesis_testing_worksheet.docx">Link
                                to solution in GitHub:</a></p>
                        <br>
                    </div>
                    <div class="summary_mearures_worksheet">
                        <header>
                            <h2 id="section9">9. Summary Measures Worksheet</h2>
                        </header>
                        <p><a
                                href="https://github.com/dasing21/eportfolio/tree/main/research_methods/hypothesis_testing_worksheet/summary_mearures_worksheet.docx">Link
                                to solution in GitHub:</a></p>
                        <br>
                    </div>
                    <div class="analysing_datasets">
                        <header>
                            <h2 id="section10">10. Analysing Datasets</h2>
                        </header>
                        <p><a
                                href="https://github.com/dasing21/eportfolio/tree/main/research_methods/analysing_datasets/analysing_datasets.docx">Link
                                to solution in GitHub:</a></p>
                        <br>
                    </div>
                    <div class="analysing_bar_charts_in_exel">
                        <header>
                            <h2 id="section11">11. Analysing Bar Charts in Excel</h2>
                        </header>
                        <p><a
                                href="https://github.com/dasing21/eportfolio/tree/main/research_methods/analysing_bar_charts_in_exel/analysing_bar_charts_in_exel.docx">Link
                                to solution in GitHub:</a></p>
                        <br>
                    </div>

            </section>
        </div>
        <!-- Contact -->
        <section id="contact">
            <div class="inner">
                <section>
                    <form method="post" action="#">
                        <div class="fields">
                            <div class="field half">
                                <label for="name">Name</label>
                                <input type="text" name="name" id="name" />
                            </div>
                            <div class="field half">
                                <label for="email">Email</label>
                                <input type="text" name="email" id="email" />
                            </div>
                            <div class="field">
                                <label for="message">Message</label>
                                <textarea name="message" id="message" rows="6"></textarea>
                            </div>
                        </div>
                        <ul class="actions">
                            <li><input type="submit" value="Send Message" class="primary" /></li>
                            <li><input type="reset" value="Clear" /></li>
                        </ul>
                    </form>
                </section>
                <section class="split">
                    <section>
                        <div class="contact-method">
                            <span class="icon solid alt fa-envelope"></span>
                            <h3>Email</h3>
                            <a href="#">information@untitled.tld</a>
                        </div>
                    </section>
                    <section>
                        <div class="contact-method">
                            <span class="icon solid alt fa-phone"></span>
                            <h3>Phone</h3>
                            <span>(000) 000-0000 x12387</span>
                        </div>
                    </section>
                    <section>
                        <div class="contact-method">
                            <span class="icon solid alt fa-home"></span>
                            <h3>Address</h3>
                            <span>1234 Somewhere Road #5432<br />
                                Nashville, TN 00000<br />
                                United States of America</span>
                        </div>
                    </section>
                </section>
            </div>
        </section>

        <!-- Footer -->
        <footer id="footer">
            <div class="inner">
                <ul class="icons">
                    <li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
                    <li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
                    <li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
                    <li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
                    <li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
                </ul>
                <ul class="copyright">
                    <li>&copy; Untitled</li>
                    <li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
                </ul>
            </div>
        </footer>

    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>

</body>

</html>